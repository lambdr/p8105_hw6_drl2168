---
title: "Homework 6"
author: "Derek Lamb"
date: "`r Sys.Date()`"
output: github_document
---
### Load packages
```{r load packages and default options, message = FALSE}
# Load packages
library(tidyverse)
library(broom)
library(modelr)

# Set default figure options
knitr::opts_chunk$set(
  fig.width = 6,
  out.width = "90%"
)

theme_set(theme_bw() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

# Problem 1
I imported the data using similar code to that which I wrote in HW5, but with a few additional cleaning steps for this problem. The final data set considers only 5 variables: the city & state of the homicide, whether the case was solved, and victim demographics (age, race, sex).
```{r import homicide data, message = FALSE, warning = FALSE}
df_homicide <- read_csv("data/homicide-data.csv", 
                        na = "Unknown") |> 
  mutate(
    state = str_to_upper(state),
    city_state = str_c(city, ", ", state),
    solved = case_when(
      disposition == "Closed by arrest" ~ 1,
      disposition != "Closed by arrest" ~ 0
    )
    ) |> 
  filter(!city_state %in% c("Tulsa, AL", "Dallas, TX", "Phoenix, AZ", "Kansas City, MO"),
         victim_race %in% c("Black", "White")) |> 
  select(city_state, victim_age, victim_sex, victim_race, solved)
```

Now I will fit a logistic regression model to predict the odds of cases being solved by victim demographics.

```{r logistic regression on baltimore}
bmore_model = 
  df_homicide |> 
  filter(city_state == "Baltimore, MD") |> 
  glm(solved ~ victim_age + victim_race + victim_sex,
      family = binomial,
      data = _)
```

This model is stored within R. I will use `tidy()` from the `broom` package to examine it further. Calculating the adjusted odds ratios and confidence intervals in a tidy format was challenging, so I created the function below to add the values of interest to an input dataframe.

```{r function for adding or and ci to df}
or_ci = function(df){
  df = 
    df |> 
    mutate(
      ci_lower = exp(estimate - 1.96*std.error),
      or = exp(estimate),
      ci_upper = exp(estimate + 1.96*std.error)
    )
  
  return(df)
}
```

Now I will apply the `or_ci` function to the logistic regression model for Baltimore, MD.
```{r bmore or}
bmore_or_sex = 
  bmore_model |> 
  tidy() |> 
  or_ci() |> 
  filter(term == "victim_sexMale") |> 
  select(ci_lower:ci_upper)
```

The adjusted odds ratio for sex on homicide is `r bmore_or_sex |> pull(or) |> round(digits = 2)` (95% CI: `r bmore_or_sex |> pull(ci_lower) |> round(digits = 2)`, `r bmore_or_sex |> pull(ci_upper) |> round(digits = 2)`), this means that when the homicide victim is male in Baltimore, MD, the case is 57% less likely to be solved than when the victim is female, holding other demographic variables constant.


To apply this approach to the entire `df_homicide` dataframe, I will create a second function to do the processing steps outlined in the previous code chunk.

```{r or cleaning function}
clean_or = function(df){
  df = 
    df |> 
    tidy() |> 
    or_ci() |> 
    filter(term == "victim_sexMale") |> 
    select(ci_lower:ci_upper)
  
  return(df)
}
```

To check that this still works, I will again apply it to the Baltimore model.

```{r check clean_or function}
bmore_model |> 
  clean_or()
```

It still works. Now I will do this for the entire dataset, using `map` functions.

```{r ors for each df}
df_or_homicide = 
  df_homicide |> 
  group_by(city_state) |> 
  nest() |> 
  mutate(
    models = map(data, \(df) glm(solved ~ victim_age + victim_race + victim_sex,
                                family = binomial,
                                data = df)),
    odds_ratio = map(models, clean_or)
  ) |> 
  unnest(odds_ratio) |> 
  select(city_state, ci_lower:ci_upper) |> 
  ungroup()
```

```{r create adj or plot}
df_or_homicide |> 
  mutate(city_state = fct_reorder(city_state, or)) |> 
  ggplot(aes(x = or, y = city_state)) + 
  geom_point() + 
  geom_errorbarh(aes(xmin = ci_lower, xmax = ci_upper)) + 
  labs(
      title = "Adjusted Odds Ratios for Sex on Homicide Closure",
      x = " Adjusted Odds Ratio",
      y = "City & State"
  )
```

In most cities, the point estimate for the adjusted odds ratio is below 1, suggesting that homicide cases with male victims are less likely to be solved than those with female victims, holding other variables constant. In some cities, such as New York City and Baton Rouge, the odds ratio looks to be much lower than 0.5. There are three cities with ORs appreciably above 1, suggesting that homicide cases with male victims are more likely to be solved than female victims, holding other variables constant. These three cities have wide CIs that cross 1, however. Indeed, over half of these CIs cross 1, bringing the relationship between victim sex and homicide closure into question generally, though it is clear in some cities.

# Problem 2
I will pull in the data from the Central Park weather station.
```{r import noaa data}
df_weather = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2022-01-01",
    date_max = "2022-12-31") |>
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) |>
  select(name, id, everything())
```

Here is a bootstrapping function that I think will be useful.
```{r bootstrap function}
boot_samp = function(df){
  sample_frac(df, replace = TRUE)
}
```

This is what I want to happen, just 5000 times.
```{r prototype bootstrap}
df_weather |> 
  boot_samp() |> 
  lm(tmax ~ tmin + prcp, data =_) |> 
  tidy()
```

I created the dataframe I needed with 5000 samples of the weather dataframe.
```{r create bootstrap df}
df_bootstrap = 
  tibble(n_strap = 1:5000) |> 
  mutate(
    samp = map(n_strap, \(i) boot_samp(df_weather))
  )
```

I then applied a linear model to each sample, and then used both the `tidy` and `glance` functions from `broom` on the model. Both of these functions output a `p.value` column within their dataframes, so I needed to unnest and extract data one at a time. 

```{r regression on bootstrap df}
df_bootstrap =
  df_bootstrap |> 
  mutate(model = map(samp, \(df) lm(tmax ~ tmin + prcp, data = df)),
         model_glance = map(model, glance),
         model_tidy = map(model, tidy)) |> 
  unnest(model_glance) |> 
  select(n_strap, r.squared, model_tidy) |> 
  unnest(model_tidy) |> 
  select(n_strap, r.squared, term, estimate) |> 
  filter(term != "(Intercept)") |> 
  pivot_wider(
    names_from = term,
    values_from = estimate) |> 
  mutate(log_beta = log(tmin*prcp)) |> 
  select(r.squared,log_beta)
```

Some of the values of $\hat{\beta_1}*\hat{\beta_2}$ were negative, and therefore the logarithm of these values is not real. Of the 5000 bootstrap samples, `r df_bootstrap |> pull(log_beta) |> is.na() |> sum()` have `NA` $log(\hat{\beta_1}*\hat{\beta_2})$ terms. I will construct histograms for the estimated parameters, excluding the `NA` values for the $log(\hat{\beta_1}*\hat{\beta_2})$ terms.

```{r histograms of r.squared and log_beta}
df_bootstrap |> 
  ggplot(aes(x = r.squared)) +
  geom_histogram() + 
  labs(
    title = "Distribution of Bootstrap R-squared",
    x = "R-squared",
    y = "Frequency"
  )

df_bootstrap |> 
  drop_na(log_beta) |> 
  ggplot(aes(x = log_beta)) +
  geom_histogram() + 
  labs(
    title = "Distribution of Bootstrap Log Beta Product",
    x = "Log(beta1 * beta2)",
    y = "Frequency"
  ) 
```

The distribution of $R^2$ looks close to normal, with a mean around 0.92. The distribution of $log(|\hat{\beta_1}*\hat{\beta_2}|)$ is heavily left skewed, with a mode around -5. I will use quantiles to obtain confidence intervals of these estimates.

```{r cis for estimates}
df_bootstrap |> 
  pivot_longer(
    r.squared:log_beta,
    names_to = "parameter",
    values_to = "estimate"
  ) |> 
  group_by(parameter) |> 
  summarize(
    ci_lower = quantile(estimate, 0.025, na.rm = TRUE),
    ci_upper = quantile(estimate, 0.975, na.rm = TRUE)
  ) |> 
  knitr::kable(col.names = c("Parameter","CI Lower Bound", "CI Upper Bound"),
               digits = 3)
```


# Problem 3
I will import the birthweight data and convert the numeric indicators to character indicators, and then recode them as factor variables.
```{r import birthweight data, message = FALSE}
df_bwt = 
  read_csv("data/birthweight.csv") |> 
  mutate(
    babysex = case_match(
      babysex,
      1 ~ "male",
      2 ~ "female"),
    malform = case_match(
      malform,
      0 ~ "absent",
      1 ~ "present"
    ),
    mrace = case_match(
      mrace,
      1 ~ "White",
      2 ~ "Black",
      3 ~ "Asian",
      4 ~ "Puerto Rican",
      8 ~ "Other"
    ),
    frace = case_match(
      frace,
      1 ~ "White",
      2 ~ "Black",
      3 ~ "Asian",
      4 ~ "Puerto Rican",
      8 ~ "Other",
      9 ~ "Unknown"
    ),
    babysex = as.factor(babysex),
    malform = as.factor(malform),
    mrace = as.factor(mrace),
    frace = as.factor(frace))
```

I will build this model using a stepwise regression approach, using AIC to evaluate model performance. This can be performed using the `stepAIC()` function in the `MASS` package.

```{r build model}
base_model = 
  df_bwt |> 
  lm(bwt ~ ., data = _)

bwt_model = 
  base_model |> 
  MASS::stepAIC(direction = "both", trace = 0)
```

```{r evaluate model}
bwt_model |> 
  anova() |> 
  knitr::kable(digits = 3)

bwt_model |> 
  tidy() |> 
  knitr::kable(digits = 3)

bwt_model |> 
  glance() |> 
  select(-c(sigma, logLik, BIC, deviance)) |> 
  knitr::kable( digits = 3)
```

I will look at a plot of residuals vs predicted values to assess model performance.

```{r resid plot}
df_bwt |> 
  add_residuals(bwt_model) |> 
  add_predictions(bwt_model) |> 
  ggplot(aes(x = pred, y = resid)) + 
  geom_point() + 
  geom_smooth(method = "lm", formula = y ~ x) + 
  labs(
    x = "Predicted Birthweight",
    y = "Residuals"
  )
```

There are a few cases with the model underpredicting badly, particularly with children who have a low birthweight. This might be indicative of the model only performing well on the more 'typical' baby, which represents the majority of the data it was trained on. However, in general the residuals appear to not change much with predicted birthweight and be centered around zero, based upon the smoothing line.

To test the model generated by the stepwise selection approach against two pre-defined models, I will use 5000 cross validation samples and compare the RMSE distributions between models.

```{r cross validation}
df_cv = 
  df_bwt |>
  crossv_mc(5000) |> 
  mutate(
    train = map(train, as_tibble),
    test = map(test, as_tibble),
    stepwise_model = map(train, \(df) lm(
      bwt ~ babysex + bhead + blength + delwt + fincome + gaweeks + 
        mheight + mrace + parity + ppwt + smoken, data = df)),
    small_model = map(train, \(df) lm(bwt ~ blength + gaweeks, data = df)),
    interaction_model = map(train, \(df) lm(
      bwt ~ bhead + blength + babysex + bhead*blength + bhead*babysex + 
        blength*babysex + bhead*blength*babysex, data = df))
  ) |> 
  mutate(
    rmse_stepwise = map2_dbl(stepwise_model, test, 
                             \(mod, df) rmse(model = mod, data = df)),
    rmse_small = map2_dbl(small_model, test, 
                          \(mod, df) rmse(model = mod, data = df)),
    rmse_interaction = map2_dbl(interaction_model, test,
                                \(mod, df) rmse(model = mod, data = df))
  )
```

I think the warning given here is due to collinearity between some terms (in particular `ppwt` with `delwt` and `ppbmi`. I checked the VIF for the model, and the highest values where `delwt` at 4.44 and `ppwt` at 4.35. These are large but not above 5, so not too concerning, therefore I will keep all the variables determined by this stepwise approach in.

Now I will plot the RMSEs from these models to compare their performance

```{r cv plot}
df_cv |> 
  select(starts_with("rmse")) |> 
  pivot_longer(
    everything(),
    names_to = "model",
    values_to = "rmse",
    names_prefix = "rmse_"
  ) |> 
  mutate(model = fct_reorder(model, rmse)) |> 
  ggplot(aes(x = model, y = rmse)) +
  geom_boxplot() +
  labs(
    title = "RMSE Comparison Between Models",
    x = "Model",
    y = "Root Mean Square Error"
  )
```

The model built through stepwise selection has a much lower RMSE than the model with only `blength` and `gaweeks`, and offers a smaller but still substantial improvement over the interaction model with `bhead`, `blength`, and `babysex`. It is, however, the most complicated, with 11 predictors, and so depending on the application, the interaction model may be simpler and easier to communicate.
