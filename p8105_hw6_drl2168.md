Homework 6
================
Derek Lamb
2023-11-28

### Load packages

``` r
# Load packages
library(tidyverse)
library(broom)
library(modelr)

# Set default figure options
knitr::opts_chunk$set(
  fig.width = 6,
  out.width = "90%"
)

theme_set(theme_bw() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

# Problem 1

I imported the data using similar code to that which I wrote in HW5, but
with a few additional cleaning steps for this problem. The final data
set considers only 5 variables: the city & state of the homicide,
whether the case was solved, and victim demographics (age, race, sex).

``` r
df_homicide <- read_csv("data/homicide-data.csv", 
                        na = "Unknown") |> 
  mutate(
    state = str_to_upper(state),
    city_state = str_c(city, ", ", state),
    solved = case_when(
      disposition == "Closed by arrest" ~ 1,
      disposition != "Closed by arrest" ~ 0
    )
    ) |> 
  filter(!city_state %in% c("Tulsa, AL", "Dallas, TX", "Phoenix, AZ", "Kansas City, MO"),
         victim_race %in% c("Black", "White")) |> 
  select(city_state, victim_age, victim_sex, victim_race, solved)
```

Now I will fit a logistic regression model to predict the odds of cases
being solved by victim demographics.

``` r
bmore_model = 
  df_homicide |> 
  filter(city_state == "Baltimore, MD") |> 
  glm(solved ~ victim_age + victim_race + victim_sex,
      family = binomial,
      data = _)
```

This model is stored within R. I will use `tidy()` from the `broom`
package to examine it further. Calculating the adjusted odds ratios and
confidence intervals in a tidy format was challenging, so I created the
function below to add the values of interest to an input dataframe.

``` r
or_ci = function(df){
  df = 
    df |> 
    mutate(
      ci_lower = exp(estimate - 1.96*std.error),
      or = exp(estimate),
      ci_upper = exp(estimate + 1.96*std.error)
    )
  
  return(df)
}
```

Now I will apply the `or_ci` function to the logistic regression model
for Baltimore, MD.

``` r
bmore_or_sex = 
  bmore_model |> 
  tidy() |> 
  or_ci() |> 
  filter(term == "victim_sexMale") |> 
  select(ci_lower:ci_upper)
```

The adjusted odds ratio for sex on homicide is 0.43 (95% CI: 0.32,
0.56), this means that when the homicide victim is male in Baltimore,
MD, the case is 57% less likely to be solved than when the victim is
female, holding other demographic variables constant.

To apply this approach to the entire `df_homicide` dataframe, I will
create a second function to do the processing steps outlined in the
previous code chunk.

``` r
clean_or = function(df){
  df = 
    df |> 
    tidy() |> 
    or_ci() |> 
    filter(term == "victim_sexMale") |> 
    select(ci_lower:ci_upper)
  
  return(df)
}
```

To check that this still works, I will again apply it to the Baltimore
model.

``` r
bmore_model |> 
  clean_or()
```

    ## # A tibble: 1 × 3
    ##   ci_lower    or ci_upper
    ##      <dbl> <dbl>    <dbl>
    ## 1    0.325 0.426    0.558

It still works. Now I will do this for the entire dataset, using `map`
functions.

``` r
df_or_homicide = 
  df_homicide |> 
  group_by(city_state) |> 
  nest() |> 
  mutate(
    models = map(data, \(df) glm(solved ~ victim_age + victim_race + victim_sex,
                                family = binomial,
                                data = df)),
    odds_ratio = map(models, clean_or)
  ) |> 
  unnest(odds_ratio) |> 
  select(city_state, ci_lower:ci_upper) |> 
  ungroup()
```

``` r
df_or_homicide |> 
  mutate(city_state = fct_reorder(city_state, or)) |> 
  ggplot(aes(x = or, y = city_state)) + 
  geom_point() + 
  geom_errorbarh(aes(xmin = ci_lower, xmax = ci_upper)) + 
  labs(
      title = "Adjusted Odds Ratios for Sex on Homicide Closure",
      x = " Adjusted Odds Ratio",
      y = "City & State"
  )
```

<img src="p8105_hw6_drl2168_files/figure-gfm/create adj or plot-1.png" width="90%" />

In most cities, the point estimate for the adjusted odds ratio is below
1, suggesting that homicide cases with male victims are less likely to
be solved than those with female victims, holding other variables
constant. In some cities, such as New York City and Baton Rouge, the
odds ratio looks to be much lower than 0.5. There are three cities with
ORs appreciably above 1, suggesting that homicide cases with male
victims are more likely to be solved than female victims, holding other
variables constant. These three cities have wide CIs that cross 1,
however. Indeed, over half of these CIs cross 1, bringing the
relationship between victim sex and homicide closure into question
generally, though it is clear in some cities.

# Problem 2

I will pull in the data from the Central Park weather station.

``` r
df_weather = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2022-01-01",
    date_max = "2022-12-31") |>
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) |>
  select(name, id, everything())
```

    ## using cached file: /Users/Derek/Library/Caches/org.R-project.R/R/rnoaa/noaa_ghcnd/USW00094728.dly

    ## date created (size, mb): 2023-09-28 10:20:09.047204 (8.524)

    ## file min/max dates: 1869-01-01 / 2023-09-30

Here is a bootstrapping function that I think will be useful.

``` r
boot_samp = function(df){
  sample_frac(df, replace = TRUE)
}
```

This is what I want to happen, just 5000 times.

``` r
df_weather |> 
  boot_samp() |> 
  lm(tmax ~ tmin + prcp, data =_) |> 
  tidy()
```

    ## # A tibble: 3 × 5
    ##   term        estimate std.error statistic   p.value
    ##   <chr>          <dbl>     <dbl>     <dbl>     <dbl>
    ## 1 (Intercept) 8.25       0.252     32.7    4.31e-110
    ## 2 tmin        0.991      0.0184    54.0    2.75e-175
    ## 3 prcp        0.000106   0.00195    0.0545 9.57e-  1

I created the dataframe I needed with 5000 samples of the weather
dataframe.

``` r
df_bootstrap = 
  tibble(n_strap = 1:5000) |> 
  mutate(
    samp = map(n_strap, \(i) boot_samp(df_weather))
  )
```

I then applied a linear model to each sample, and then used both the
`tidy` and `glance` functions from `broom` on the model. Both of these
functions output a `p.value` column within their dataframes, so I needed
to unnest and extract data one at a time.

``` r
df_bootstrap =
  df_bootstrap |> 
  mutate(model = map(samp, \(df) lm(tmax ~ tmin + prcp, data = df)),
         model_glance = map(model, glance),
         model_tidy = map(model, tidy)) |> 
  unnest(model_glance) |> 
  select(n_strap, r.squared, model_tidy) |> 
  unnest(model_tidy) |> 
  select(n_strap, r.squared, term, estimate) |> 
  filter(term != "(Intercept)") |> 
  pivot_wider(
    names_from = term,
    values_from = estimate) |> 
  mutate(log_beta = log(tmin*prcp)) |> 
  select(r.squared,log_beta)
```

    ## Warning: There was 1 warning in `mutate()`.
    ## ℹ In argument: `log_beta = log(tmin * prcp)`.
    ## Caused by warning in `log()`:
    ## ! NaNs produced

Some of the values of $\hat{\beta_1}*\hat{\beta_2}$ were negative, and
therefore the logarithm of these values is not real. Of the 5000
bootstrap samples, 3359 have `NA` $log(\hat{\beta_1}*\hat{\beta_2})$
terms. I will construct histograms for the estimated parameters,
excluding the `NA` values for the $log(\hat{\beta_1}*\hat{\beta_2})$
terms.

``` r
df_bootstrap |> 
  ggplot(aes(x = r.squared)) +
  geom_histogram() + 
  labs(
    title = "Distribution of Bootstrap R-squared",
    x = "R-squared",
    y = "Frequency"
  )
```

    ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.

<img src="p8105_hw6_drl2168_files/figure-gfm/histograms of r.squared and log_beta-1.png" width="90%" />

``` r
df_bootstrap |> 
  drop_na(log_beta) |> 
  ggplot(aes(x = log_beta)) +
  geom_histogram() + 
  labs(
    title = "Distribution of Bootstrap Log Beta Product",
    x = "Log(beta1 * beta2)",
    y = "Frequency"
  ) 
```

    ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.

<img src="p8105_hw6_drl2168_files/figure-gfm/histograms of r.squared and log_beta-2.png" width="90%" />

The distribution of $R^2$ looks close to normal, with a mean around
0.92. The distribution of $log(|\hat{\beta_1}*\hat{\beta_2}|)$ is
heavily left skewed, with a mode around -5. I will use quantiles to
obtain confidence intervals of these estimates.

``` r
df_bootstrap |> 
  pivot_longer(
    r.squared:log_beta,
    names_to = "parameter",
    values_to = "estimate"
  ) |> 
  group_by(parameter) |> 
  summarize(
    ci_lower = quantile(estimate, 0.025, na.rm = TRUE),
    ci_upper = quantile(estimate, 0.975, na.rm = TRUE)
  ) |> 
  knitr::kable(col.names = c("Parameter","CI Lower Bound", "CI Upper Bound"),
               digits = 3)
```

| Parameter | CI Lower Bound | CI Upper Bound |
|:----------|---------------:|---------------:|
| log_beta  |         -8.964 |         -4.577 |
| r.squared |          0.889 |          0.940 |

# Problem 3

I will import the birthweight data and convert the numeric indicators to
character indicators, and then recode them as factor variables.

``` r
df_bwt = 
  read_csv("data/birthweight.csv") |> 
  mutate(
    babysex = case_match(
      babysex,
      1 ~ "male",
      2 ~ "female"),
    malform = case_match(
      malform,
      0 ~ "absent",
      1 ~ "present"
    ),
    mrace = case_match(
      mrace,
      1 ~ "White",
      2 ~ "Black",
      3 ~ "Asian",
      4 ~ "Puerto Rican",
      8 ~ "Other"
    ),
    frace = case_match(
      frace,
      1 ~ "White",
      2 ~ "Black",
      3 ~ "Asian",
      4 ~ "Puerto Rican",
      8 ~ "Other",
      9 ~ "Unknown"
    ),
    babysex = as.factor(babysex),
    malform = as.factor(malform),
    mrace = as.factor(mrace),
    frace = as.factor(frace))
```

I will build this model using a stepwise regression approach, using AIC
to evaluate model performance. This can be performed using the
`stepAIC()` function in the `MASS` package.

``` r
base_model = 
  df_bwt |> 
  lm(bwt ~ ., data = _)

bwt_model = 
  base_model |> 
  MASS::stepAIC(direction = "both", trace = 0)
```

``` r
bwt_model |> 
  anova() |> 
  knitr::kable(digits = 3)
```

|           |   Df |       Sum Sq |       Mean Sq |  F value | Pr(\>F) |
|:----------|-----:|-------------:|--------------:|---------:|--------:|
| babysex   |    1 |    8547633.5 |    8547633.55 |  115.251 |   0.000 |
| bhead     |    1 | 628838119\.6 | 628838119\.63 | 8478.899 |   0.000 |
| blength   |    1 | 140213755\.0 | 140213755\.01 | 1890.563 |   0.000 |
| delwt     |    1 |    8647157.7 |    8647157.70 |  116.593 |   0.000 |
| fincome   |    1 |    4845845.1 |    4845845.06 |   65.339 |   0.000 |
| gaweeks   |    1 |    5936110.4 |    5936110.42 |   80.039 |   0.000 |
| mheight   |    1 |     883286.8 |     883286.83 |   11.910 |   0.001 |
| mrace     |    3 |   11463486.3 |    3821162.11 |   51.522 |   0.000 |
| parity    |    1 |     481225.0 |     481224.98 |    6.489 |   0.011 |
| ppwt      |    1 |    2735313.7 |    2735313.67 |   36.881 |   0.000 |
| smoken    |    1 |    5073848.7 |    5073848.67 |   68.413 |   0.000 |
| Residuals | 4328 | 320986411\.6 |      74165.07 |       NA |      NA |

``` r
bwt_model |> 
  tidy() |> 
  knitr::kable(digits = 3)
```

| term              |  estimate | std.error | statistic | p.value |
|:------------------|----------:|----------:|----------:|--------:|
| (Intercept)       | -6145.151 |   141.950 |   -43.291 |   0.000 |
| babysexmale       |   -28.558 |     8.455 |    -3.378 |   0.001 |
| bhead             |   130.777 |     3.447 |    37.944 |   0.000 |
| blength           |    74.947 |     2.019 |    37.120 |   0.000 |
| delwt             |     4.107 |     0.392 |    10.475 |   0.000 |
| fincome           |     0.318 |     0.175 |     1.820 |   0.069 |
| gaweeks           |    11.592 |     1.462 |     7.929 |   0.000 |
| mheight           |     6.594 |     1.785 |     3.694 |   0.000 |
| mraceBlack        |   -63.906 |    42.366 |    -1.508 |   0.132 |
| mracePuerto Rican |   -25.791 |    45.350 |    -0.569 |   0.570 |
| mraceWhite        |    74.887 |    42.315 |     1.770 |   0.077 |
| parity            |    96.305 |    40.336 |     2.388 |   0.017 |
| ppwt              |    -2.676 |     0.427 |    -6.261 |   0.000 |
| smoken            |    -4.843 |     0.586 |    -8.271 |   0.000 |

``` r
bwt_model |> 
  glance() |> 
  select(-c(sigma, logLik, BIC, deviance)) |> 
  knitr::kable( digits = 3)
```

| r.squared | adj.r.squared | statistic | p.value |  df |      AIC | df.residual | nobs |
|----------:|--------------:|----------:|--------:|----:|---------:|------------:|-----:|
|     0.718 |         0.717 |   848.073 |       0 |  13 | 61029.44 |        4328 | 4342 |

I will look at a plot of residuals vs predicted values to assess model
performance.

``` r
df_bwt |> 
  add_residuals(bwt_model) |> 
  add_predictions(bwt_model) |> 
  ggplot(aes(x = pred, y = resid)) + 
  geom_point() + 
  geom_smooth(method = "lm", formula = y ~ x) + 
  labs(
    x = "Predicted Birthweight",
    y = "Residuals"
  )
```

<img src="p8105_hw6_drl2168_files/figure-gfm/resid plot-1.png" width="90%" />

There are a few cases with the model underpredicting badly, particularly
with children who have a low birthweight. This might be indicative of
the model only performing well on the more ‘typical’ baby, which
represents the majority of the data it was trained on. However, in
general the residuals appear to not change much with predicted
birthweight and be centered around zero, based upon the smoothing line.

To test the model generated by the stepwise selection approach against
two pre-defined models, I will use 5000 cross validation samples and
compare the RMSE distributions between models.

``` r
df_cv = 
  df_bwt |>
  crossv_mc(5000) |> 
  mutate(
    train = map(train, as_tibble),
    test = map(test, as_tibble),
    stepwise_model = map(train, \(df) lm(
      bwt ~ babysex + bhead + blength + delwt + fincome + gaweeks + 
        mheight + mrace + parity + ppwt + smoken, data = df)),
    small_model = map(train, \(df) lm(bwt ~ blength + gaweeks, data = df)),
    interaction_model = map(train, \(df) lm(
      bwt ~ bhead + blength + babysex + bhead*blength + bhead*babysex + 
        blength*babysex + bhead*blength*babysex, data = df))
  ) |> 
  mutate(
    rmse_stepwise = map2_dbl(stepwise_model, test, 
                             \(mod, df) rmse(model = mod, data = df)),
    rmse_small = map2_dbl(small_model, test, 
                          \(mod, df) rmse(model = mod, data = df)),
    rmse_interaction = map2_dbl(interaction_model, test,
                                \(mod, df) rmse(model = mod, data = df))
  )
```

    ## Warning: There were 42 warnings in `mutate()`.
    ## The first warning was:
    ## ℹ In argument: `rmse_stepwise = map2_dbl(...)`.
    ## Caused by warning in `predict.lm()`:
    ## ! prediction from rank-deficient fit; attr(*, "non-estim") has doubtful cases
    ## ℹ Run `dplyr::last_dplyr_warnings()` to see the 41 remaining warnings.

I think the warning given here is due to collinearity between some terms
(in particular `ppwt` with `delwt` and `ppbmi`. I checked the VIF for
the model, and the highest values where `delwt` at 4.44 and `ppwt` at
4.35. These are large but not above 5, so not too concerning, therefore
I will keep all the variables determined by this stepwise approach in.

Now I will plot the RMSEs from these models to compare their performance

``` r
df_cv |> 
  select(starts_with("rmse")) |> 
  pivot_longer(
    everything(),
    names_to = "model",
    values_to = "rmse",
    names_prefix = "rmse_"
  ) |> 
  mutate(model = fct_reorder(model, rmse)) |> 
  ggplot(aes(x = model, y = rmse)) +
  geom_boxplot() +
  labs(
    title = "RMSE Comparison Between Models",
    x = "Model",
    y = "Root Mean Square Error"
  )
```

<img src="p8105_hw6_drl2168_files/figure-gfm/cv plot-1.png" width="90%" />

The model built through stepwise selection has a much lower RMSE than
the model with only `blength` and `gaweeks`, and offers a smaller but
still substantial improvement over the interaction model with `bhead`,
`blength`, and `babysex`. It is, however, the most complicated, with 11
predictors, and so depending on the application, the interaction model
may be simpler and easier to communicate.
